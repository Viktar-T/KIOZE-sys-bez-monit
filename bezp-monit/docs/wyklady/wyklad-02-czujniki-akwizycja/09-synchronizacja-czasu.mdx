---
title: "Synchronizacja czasu: NTP/PTP"
sidebar_position: 9
---

import { 
  SlideContainer, 
  Slide, 
  KeyPoints, 
  SupportingDetails, 
  InstructorNotes,
  VisualSeparator,
  LearningObjective,
  KeyConcept,
  Example
} from '@site/src/components/SlideComponents';
import { InteractiveQuiz } from '@site/src/components/InteractiveQuiz';

<LearningObjective>
Po tej sekcji student potrafi:
- WyjaÅ›niÄ‡ znaczenie synchronizacji czasu w systemach rozproszonych (SCADA, IIoT, multi-site)
- PorÃ³wnaÄ‡ protokoÅ‚y NTP i PTP (IEEE 1588) pod kÄ…tem dokÅ‚adnoÅ›ci, wymagaÅ„ sieciowych i zastosowaÅ„
- ZaprojektowaÄ‡ hierarchiÄ™ serwerÃ³w czasu (stratum, master/slave) dla instalacji OZE
- ZidentyfikowaÄ‡ typowe problemy synchronizacji (drift, jitter, asymmetric delays) i zastosowaÄ‡ rozwiÄ…zania
</LearningObjective>

<SlideContainer>

<Slide title="â° Dlaczego synchronizacja czasu jest krytyczna?" type="info">

<KeyPoints title="ğŸ“‹ Znaczenie spÃ³jnego czasu w systemach OZE">

**Problem: Systemy rozproszone bez synchronizacji**

Typowa instalacja OZE (np. farma PV 10 MWp) ma:
- 500+ czujnikÃ³w (string monitors, pyranometry, temp, wiatr)
- 20-50 inwerterÃ³w (kaÅ¼dy z wÅ‚asnym zegarkiem)
- 5-10 gateway devices (edge computing)
- 1-2 servery SCADA/historian
- PoÅ‚Ä…czenia: Modbus, OPC UA, MQTT, HTTP/REST

**KaÅ¼de urzÄ…dzenie ma wÅ‚asny zegar** â†’ drift (zmiana) 10-100 ppm (parts per million)
- 10 ppm = **0.86 s/day** drift
- 100 ppm = **8.6 s/day** drift

Po tygodniu bez synchronizacji: **rÃ³Å¼nice do 1 minuty** miÄ™dzy urzÄ…dzeniami!

---

### Konsekwencje braku synchronizacji:

**1. NiemoÅ¼noÅ›Ä‡ korelacji zdarzeÅ„**

PrzykÅ‚ad: Analiza wyÅ‚Ä…czenia inwertera
- Inwerter wyÅ‚Ä…czyÅ‚ siÄ™ @ 14:32:17 (wedÅ‚ug jego zegara)
- Pyranometr zanotowaÅ‚ spadek G @ 14:32:45 (wedÅ‚ug jego zegara)
- **Pytanie**: Czy wyÅ‚Ä…czenie spowodowaÅ‚o spadek G (cieÅ„), czy odwrotnie (chmura â†’ wyÅ‚Ä…czenie przez undervoltage)?
- **OdpowiedÅº**: **Nie wiemy** jeÅ›li zegary nie sÄ… zsynchronizowane Â±1 s!

**2. BÅ‚Ä™dy w obliczeniach energii (billing errors)**

Performance Ratio:
$$
PR = \frac{E_{\text{actual}}(t_1, t_2)}{P_{\text{STC}} \times \int_{t_1}^{t_2} G(t) \, dt}
$$

JeÅ›li t_1, t_2 rÃ³Å¼niÄ… siÄ™ miÄ™dzy E i G (rÃ³Å¼ne zegary) â†’ bÅ‚Ä…d do Â±5-10% w PR!

**3. FaÅ‚szywe alarmy / Missed events**

SOE (Sequence of Events) w SCADA:
- Alarm "Undervoltage Grid" @ 08:15:23.456
- Alarm "Inverter Trip" @ 08:15:23.123

KtÃ³ry byÅ‚ PIERWSZY? JeÅ›li dryft >0.5 s â†’ **nie wiadomo** (causa vs. effect)

**4. Regulacyjne/audytowe compliance**

Normy (IEC 61850, IEEE 1815 DNP3) **wymagajÄ…** synchronizacji:
- **IEC 61850**: Â±1 ms dla protection events
- **ISO 50001** (energy management): Â±10 s dla billing
- **GDPR audit logs**: Â±1 s dla cybersecurity events

---

### Rodzaje aplikacji i wymagana dokÅ‚adnoÅ›Ä‡:

| Aplikacja | Wymagana dokÅ‚adnoÅ›Ä‡ | ProtokÃ³Å‚ | PrzykÅ‚ad |
|-----------|---------------------|----------|----------|
| **SCADA trends** (trendowanie) | Â±10 s - Â±1 min | NTP | Grafana dashboards, InfluxDB |
| **Energy billing** (rozliczenia) | Â±1 s | NTP | Liczniki energii, PR calculations |
| **Event correlation** (analiza zdarzeÅ„) | Â±100 ms | NTP (stratum 2) | SOE analysis, alarm correlation |
| **Grid protection** (ochrony) | Â±1 ms | PTP (IEEE 1588) | IEC 61850 substations, synchrophasors |
| **High-speed data acquisition** (fast DAQ) | Â±1 Âµs | PTP w/ hardware timestamp | Synchronized waveform capture (PMU) |
| **Cybersecurity logs** | Â±1 s | NTP | Audit trails, intrusion detection |

</KeyPoints>

<SupportingDetails title="ğŸ” Typowe ÅºrÃ³dÅ‚a bÅ‚Ä™dÃ³w czasu">

### 1. **Clock drift (dryft zegara)**

**Przyczyna**: NiedokÅ‚adnoÅ›Ä‡ oscylatora (crystal)
- Cheap quartz: 50-100 ppm (Â±8 s/day)
- Standard quartz (TCXO): 1-10 ppm (Â±0.1-0.9 s/day)
- High-precision (OCXO): 0.01-0.1 ppm (Â±0.001-0.01 s/day)

**RozwiÄ…zanie**: Regularna synchronizacja (NTP co 10-60 min, PTP continuous)

### 2. **Network delays (opÃ³Åºnienia sieciowe)**

Packet transit time zmienne (jitter):
- LAN: 0.1-1 ms (Ethernet, switch latency)
- WAN: 10-100 ms (routing, congestion)
- Wireless (WiFi): 5-50 ms (collision, retransmission)

**RozwiÄ…zanie**: NTP algorytm kompensuje asymmetric delays, PTP wymaga symmetric network

### 3. **Temperature drift**

CzÄ™stotliwoÅ›Ä‡ oscylatora zmienia siÄ™ z T:
- Standard crystal: Â±0.035 ppm/Â°C
- W turbinie wiatrowej (gondola -30Â°C do +60Â°C) â†’ drift do Â±3 ppm (Â±0.26 s/day)

**RozwiÄ…zanie**: TCXO (Temperature-Compensated Crystal Oscillator) lub frequent sync

### 4. **Software delays (kernel jitter)**

OS scheduler latency:
- Linux (standard kernel): 1-10 ms jitter
- Linux (real-time, PREEMPT_RT): 50-100 Âµs
- RTOS (VxWorks, QNX): 10-50 Âµs

**RozwiÄ…zanie**: Hardware timestamping (PTP), kernel tuning

</SupportingDetails>

<InstructorNotes>

**Czas**: 12-14 min

**Przebieg**:
1. Problem braku synchronizacji (4 min) â€“ przykÅ‚ad korelacji zdarzeÅ„
2. Konsekwencje (3 min) â€“ billing errors, false alarms, compliance
3. Wymagana dokÅ‚adnoÅ›Ä‡ dla aplikacji (2 min) â€“ tabela
4. Å¹rÃ³dÅ‚a bÅ‚Ä™dÃ³w (2 min) â€“ drift, network delays, temperature
5. Q&A (2 min)

**Punkty kluczowe**:
- **Drift 10-100 ppm = kilka sekund/dzieÅ„** â€“ szybko akumuluje siÄ™
- **Korelacja zdarzeÅ„ wymaga Â±100 ms** â€“ inaczej causa/effect unclear
- **Billing/PR wymaga Â±1 s** â€“ wiÄ™kszy bÅ‚Ä…d = disputes z inwestorami
- **Grid protection = Â±1 ms** (PTP) vs. SCADA trends = Â±10 s (NTP)

**Demonstracja praktyczna**:
- PokaÅ¼ wykres: drift zegara przez 1 tydzieÅ„ bez sync (exponential divergence)
- SOE log z SCADA â€“ jak timestamp pomaga w root cause analysis
- ntpq -p command (Linux) â€“ shows current time servers and offsets

**MateriaÅ‚y pomocnicze**:
- RFC 5905 (NTPv4 specification)
- IEEE 1588-2019 (PTPv2.1 standard)
- IEC 61850-5: Communication requirements for functions and device models (timing)

**Typowe bÅ‚Ä™dy studenckie**:
- MyÅ›lenie, Å¼e "zegar komputera jest dokÅ‚adny" â€“ NO! Drift 50-100 ppm typowy
- Ignorowanie timezone (UTC vs. local) â€“ ZAWSZE uÅ¼ywaj UTC w logach/bazach
- Stosowanie system time() call do timestampÃ³w high-frequency â€“ jitter 1-10 ms

**Pytania studenckie**:
- Q: Czemu nie uÅ¼yÄ‡ GPS do synchronizacji (dokÅ‚adnoÅ›Ä‡ &lt;100 ns)?
- A: MOÅ»NA (GPS clock modules ~100-500 EUR). Ale: (1) wymaga anteny outdoor (w gondoli OK, w data center NO), (2) GNSS jamming/spoofing risk. W praktyce: GPS dla master, NTP/PTP dystrybuuje do slaves.

- Q: Co to jest "leap second"?
- A: UTC periodic adjustment (co 1-2 lata) +1 s, bo rotation Ziemi zwalnia. NTP/PTP handle automatically, ale legacy systems mogÄ… mieÄ‡ problemy (crashes). Last leap second: 2016-12-31 23:59:60.

</InstructorNotes>

</Slide>

<VisualSeparator type="technical" />

<Slide title="ğŸŒ NTP vs. PTP â€“ porÃ³wnanie protokoÅ‚Ã³w" type="tip">

<KeyConcept title="Network Time Protocol (NTP) â€“ RFC 5905">

**Architektura hierarchiczna (stratum):**

```mermaid
graph TB
    S0[Stratum 0<br/>Atomic clock, GPS<br/>Â±10 ns] --> S1A[Stratum 1<br/>NTP Server A<br/>Â±1 Âµs]
    S0 --> S1B[Stratum 1<br/>NTP Server B<br/>Â±1 Âµs]
    
    S1A --> S2A[Stratum 2<br/>Corporate NTP<br/>Â±10 ms LAN]
    S1B --> S2A
    S1A --> S2B[Stratum 2<br/>ISP NTP<br/>Â±50 ms WAN]
    
    S2A --> S3[Stratum 3<br/>Edge devices<br/>Â±50-100 ms]
    S2B --> S3
    
    S3 --> S4[Stratum 4+<br/>Sensors, PLCs<br/>Â±100-500 ms]
    
    style S0 fill:#ffd700
    style S1A fill:#ffeb99
    style S1B fill:#ffeb99
    style S2A fill:#ffffcc
    style S3 fill:#e6ffe6
    style S4 fill:#ccffcc
```

**DokÅ‚adnoÅ›Ä‡ typowa:**
- **Stratum 1**: Â±1-10 Âµs (bezpoÅ›rednio od GPS/atomic)
- **Stratum 2** (LAN): Â±1-10 ms
- **Stratum 3** (WAN, internet): Â±10-100 ms
- **Stratum 4+**: Â±100-500 ms (za duÅ¼o hopÃ³w)

**Algorytm synchronizacji** (uproszczony):
1. Client wysyÅ‚a request â†’ Server (timestamp T1)
2. Server odbiera (T2), wysyÅ‚a response (T3)
3. Client odbiera (T4)
4. **Obliczenie offset**: Î¸ = [(T2-T1) + (T3-T4)] / 2
5. **Obliczenie delay**: Î´ = (T4-T1) - (T3-T2)

**Korekta zegara**: Stepwise (jeÅ›li |Î¸| &gt;128 ms) lub slew (stopniowa, &lt;128 ms)

---

**Zalety NTP:**
- âœ… Prosty, szeroko wspierany (kaÅ¼dy OS, device)
- âœ… DziaÅ‚a przez Internet/WAN (toleruje asymmetric routing)
- âœ… Algorytm outlier rejection (wybiera best servers)
- âœ… Cheap (software-only, no special hardware)

**Wady NTP:**
- âŒ DokÅ‚adnoÅ›Ä‡ limited do Â±1-10 ms (LAN), Â±10-100 ms (WAN)
- âŒ Software timestamps (kernel jitter 1-10 ms)
- âŒ Nie nadaje siÄ™ do sub-millisecond applications

</KeyConcept>

<SupportingDetails title="âš™ï¸ Precision Time Protocol (PTP) â€“ IEEE 1588">

**Architektura master-slave:**

```mermaid
graph LR
    GM[Grandmaster Clock<br/>GPS/atomic<br/>Â±10 ns] --> SW1[PTP-aware<br/>Switch 1]
    SW1 --> SW2[PTP-aware<br/>Switch 2]
    SW1 --> S1[Slave 1<br/>DAQ device<br/>Â±1 Âµs]
    SW2 --> S2[Slave 2<br/>Camera<br/>Â±1 Âµs]
    SW2 --> S3[Slave 3<br/>PLC<br/>Â±1 Âµs]
    
    style GM fill:#ffd700
    style SW1 fill:#87ceeb
    style SW2 fill:#87ceeb
    style S1 fill:#90ee90
    style S2 fill:#90ee90
    style S3 fill:#90ee90
```

**Kluczowe cechy:**
- **Hardware timestamping**: Timestamps at PHY layer (Ethernet MAC), nie w kernelu â†’ eliminuje software jitter
- **Transparent clocks**: PTP-aware switches korygujÄ… delays â†’ eliminuje switch latency uncertainties
- **Peer delay measurement**: KaÅ¼dy link mierzy propagation delay niezaleÅ¼nie

**Message exchange** (Sync + Follow_Up + Delay_Req + Delay_Resp):
1. Master â†’ Sync message (timestamp T1 @ PHY)
2. Master â†’ Follow_Up (zawiera precyzyjny T1)
3. Slave â†’ Delay_Req (timestamp T3)
4. Master â†’ Delay_Resp (zawiera T4 = receive time of Delay_Req)

**Obliczenia** (similar to NTP ale hardware timestamps):
- Offset: Î¸ = [(T2-T1) - (T4-T3)] / 2
- Mean path delay: Î´ = [(T2-T1) + (T4-T3)] / 2

---

**DokÅ‚adnoÅ›Ä‡ PTP:**
- **Hardware timestamping**: Â±100 ns - Â±1 Âµs (typowo Â±200-500 ns)
- **Software timestamping** (fallback): Â±10-100 Âµs (lepsze niÅ¼ NTP, ale gorsze niÅ¼ hardware)

**Zalety PTP:**
- âœ… DokÅ‚adnoÅ›Ä‡ sub-microsecond (Â±100 ns - Â±1 Âµs)
- âœ… Hardware timestamps â†’ eliminate software jitter
- âœ… Scalable (hundreds of slaves per master)
- âœ… Deterministic (w przeciwieÅ„stwie do NTP ktÃ³ry uÅ¼ywa statistics)

**Wady PTP:**
- âŒ Wymaga PTP-aware network infrastructure (switches, NICs) â€“ **KOSZTOWNE** (+30-50% vs. standard switches)
- âŒ Symmetric network path required (PTP zaÅ‚oÅ¼enie: delay Masterâ†’Slave = Slaveâ†’Master)
- âŒ NIE dziaÅ‚a przez Internet/WAN (routing asymmetry)
- âŒ Complexity: Configuration, VLAN setup, multicast/unicast choice

---

### PorÃ³wnanie tabelaryczne:

| Parametr | NTP | PTP (hardware) |
|----------|-----|----------------|
| **DokÅ‚adnoÅ›Ä‡ (LAN)** | Â±1-10 ms | Â±100 ns - Â±1 Âµs |
| **Timestamping** | Software (kernel) | Hardware (PHY/MAC) |
| **Network req.** | Standard (any) | PTP-aware switches |
| **WAN support** | âœ… YES | âŒ NO (symmetric only) |
| **Koszt infrastruktury** | $ (software) | $$$ (HW switches, NICs) |
| **Complexity** | Niski | Åšredni-Wysoki |
| **Zastosowanie** | SCADA, IoT, general | Industrial automation, test/measurement, grid protection |

</SupportingDetails>

<Example title="Implementacja hierarchii NTP â€“ farma PV 50 MWp">

**Architektura:**

```
Stratum 0: GPS clock module (outdoor, roof data center)
    â†“
Stratum 1: 2Ã— NTP servers (Linux, redundancja)
    â†“
Stratum 2: Edge gateways (50Ã— w terenie, per 1 MWp)
    â†“
Stratum 3: Sensors, inverters, PLCs (5000+ devices)
```

**SzczegÃ³Å‚y implementacji:**

**Stratum 1 (NTP servers):**
- Hardware: 2Ã— Raspberry Pi 4 (redundancja) + GPS HAT (u-blox NEO-M8N, &lt;50 EUR)
- OS: Raspberry Pi OS + chrony (modern NTP daemon, lepszy niÅ¼ ntpd)
- Config `chrony.conf`:
```
# GPS jako reference clock
refclock SHM 0 refid GPS precision 1e-3 offset 0.5 delay 0.1
# Serve NTP dla local network
allow 192.168.0.0/16
local stratum 1
```
- Monitoring: `chronyc tracking` (check offset, drift)

**Stratum 2 (Edge gateways):**
- Hardware: Siemens SIMATIC IoT2050, Raspberry Pi 4 (w terenie)
- Config `/etc/chrony/chrony.conf`:
```
server ntp-server-1.local iburst prefer
server ntp-server-2.local iburst
pool ntp.local iburst maxsources 4
makestep 1 3  # Step if offset >1s in first 3 updates
```
- Sync interval: 64-1024 s (adaptive, zaleÅ¼nie od drift)

**Stratum 3 (Devices):**
- **Inwertery** (SMA, Fronius): Modbus register "Set Time" (write UTC timestamp co 1h)
- **String monitors**: SNMP `sysTime` set (co 10 min)
- **Dataloggers** (Campbell, Datataker): Built-in NTP client â†’ point to local gateway
- **PLCs** (Siemens, Schneider): NTP client module (opcjonalny, +200 EUR) lub Modbus time write

---

**Wyniki (po 6 miesiÄ…cach eksploatacji):**

| Stratum | Device count | Typical offset | Max offset observed |
|---------|--------------|----------------|---------------------|
| **Stratum 1** | 2 | Â±10 Âµs (GPS) | Â±50 Âµs (GPS signal loss transient) |
| **Stratum 2** | 50 | Â±3-8 ms (LAN) | Â±15 ms (peak LAN congestion) |
| **Stratum 3** | 5000 | Â±10-50 ms (Modbus/SNMP latency) | Â±200 ms (few legacy devices) |

**Korelacja zdarzeÅ„:**
- SOE (Sequence of Events) w SCADA: Â±50 ms accuracy â†’ wystarczajÄ…ce do 95% analiz
- Alarm correlation: "Grid undervoltage" @ 14:23:45.123 â†’ "Inverters trip" @ 14:23:45.201-14:23:45.389 (78-266 ms later) â†’ **CLEAR causa-effect**

**Koszty:**
- **CAPEX**: 2Ã— GPS modules + Raspberry Pi = 2Ã—(50+80) EUR = **260 EUR**
- **OPEX**: Monitoring (1h/month) = **50 EUR/year**
- **Total 5-year TCO**: 260 + 5Ã—50 = **510 EUR**

**ROI:**
- UnikniÄ™to 1 dispute z inwestorem (PR calculation mismatch przez timestamp errors) â†’ koszt potencjalny: **10 000 EUR** (prawnik, audyt)
- **Zwrot: >19Ã—** w jednym incydencie

---

**Lessons learned:**
1. **GPS antenna placement kluczowy** â€“ roof, clear sky view, NO obstructions (drzewa, maszty)
2. **Redundancja Stratum 1** (2 servery) â€“ jeÅ›li 1 GPS fail, drugi przejmuje
3. **Monitoring drift** â€“ dashboard Grafana z `chronyc tracking` metrics â†’ early warning dryftu
4. **Firmware updates** devices â†’ czasem reset time config, trzeba re-apply
5. **Legacy devices** (old inverters) nie majÄ… NTP â†’ manual Modbus time sync script (cron co 1h)

</Example>

<InstructorNotes>

**Czas**: 16-18 min

**Przebieg**:
1. NTP â€“ architektura stratum, algorytm (5 min)
2. PTP â€“ hardware timestamping, wymagania (4 min)
3. PorÃ³wnanie NTP vs. PTP â€“ tabela (2 min)
4. Case study: Implementacja NTP w farmie PV (5 min)
5. Q&A (2 min)

**Punkty kluczowe**:
- **NTP = Â±1-10 ms, PTP = Â±100 ns-1 Âµs** â€“ rzÄ™dy wielkoÅ›ci rÃ³Å¼nicy
- **PTP wymaga hardware** (switches, NICs) â†’ $$$ expensive
- **NTP dla 90% aplikacji OZE wystarczy** (SCADA, billing)
- **PTP dla grid protection, synchrophasors** (IEC 61850)

**Demonstracja praktyczna**:
- `chronyc tracking` output â€“ pokazuje offset, drift, jitter
- Wireshark capture: NTP packets (4 messages), PTP packets (Sync, Follow_Up, etc.)
- GPS antenna + Raspberry Pi + chrony â€“ live demo (jeÅ›li dostÄ™pne)

**MateriaÅ‚y pomocnicze**:
- RFC 5905 (NTPv4) â€“ official specification
- IEEE 1588-2019 â€“ PTP standard (expensive, but IEEE Xplore w uczelniach)
- Chrony documentation (https://chrony.tuxfamily.org/)
- Meinberg: "Introduction to NTP and PTP" (whitepaper, free)

**Typowe bÅ‚Ä™dy studenckie**:
- MyÅ›lenie, Å¼e NTP "synchronizuje instantly" â€“ NO! Algorytm stopniowy (slew), trwa minuty
- Stosowanie `ntpdate` (deprecated) zamiast chrony/ntpd
- Brak monitoringu drift â†’ nie wiedzÄ…, Å¼e clock desynced

**Pytania studenckie**:
- Q: Czy moÅ¼na uÅ¼ywaÄ‡ public NTP servers (pool.ntp.org) zamiast local GPS?
- A: TAK dla non-critical (Â±10-100 ms accuracy OK). NIE dla critical (billing, protection) â€“ chcesz local stratum 1 (Â±1-10 ms) i kontrolÄ™ (no Internet dependency).

- Q: Co jeÅ›li GPS signal lost (jamming, antenna fail)?
- A: NTP server holdover: uÅ¼ywa last known drift correction, accuracy degrades stopniowo (Â±1 ms/day drift typical for TCXO). Po >24h bez GPS: switch to stratum 2 (use other NTP servers jako backup).

</InstructorNotes>

</Slide>

</SlideContainer>